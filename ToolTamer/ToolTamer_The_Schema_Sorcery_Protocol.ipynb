{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pbNWu7sLphIB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import List, Dict, Union, Optional\n",
        "import random\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ISbAbdb_Ects",
        "outputId": "733195d6-37e4-49c0-ebb0-fe8b7309282a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4bb2276a-cc6e-4b6d-bd4f-d7adfaab46bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4bb2276a-cc6e-4b6d-bd4f-d7adfaab46bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tool invocation.json to tool invocation.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "with open('tool invocation.json', 'r') as f:\n",
        "    data= json.load(f)"
      ],
      "metadata": {
        "id": "ip-4CnKLEDda"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESSING"
      ],
      "metadata": {
        "id": "BtgFdQM9duUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_and_normalize_schemas(system_text: str) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    arguments:system_text: raw text from the \"system\" field containing json schemas\n",
        "    returns: list of normalized function schemas (empty list if none found)\n",
        "    \"\"\"\n",
        "    schemas= []\n",
        "    #extract all json objects using regex\n",
        "    json_objects= re.findall(r'\\{\\s*\".*?\"\\s*:\\s*\\{.*?\\}\\s*\\}(?=\\s*\\{|\\s*$|\\,)', system_text, re.DOTALL)  #matches json objects till the first '}' and valid boundaries (verified by the lookahead function)\n",
        "\n",
        "    for obj in json_objects:\n",
        "        try:\n",
        "            obj= obj.strip()  #removes possible whitespaces after '}' or before '{'\n",
        "            obj= re.sub(r'\\}\\s*\\{', '},{', obj)  #add missing commas\n",
        "            obj = re.sub(r\"(?<=\\:|\\,)\\s*'\", '\"', obj)\n",
        "            obj= re.sub(r'(?<!\\\\)\"(?!\\s*[:}\\],])', r'\\\"', obj)  #escape quotes (only those which are not already escaped or followed by ':' or '}' or ']' or ',')\n",
        "\n",
        "            #parse json (try as array if multiple objects)\n",
        "            try:\n",
        "                parse_data= json.loads(obj)\n",
        "            except json.JSONDecodeError:\n",
        "                if re.search(r'^\\s*\\{.*\\}\\s*\\{', obj):\n",
        "                    parse_data= json.loads(f'[{obj}]')\n",
        "                else:\n",
        "                    raise\n",
        "\n",
        "            #normalize to list format\n",
        "            functions= parse_data if isinstance(parse_data, list) else [parse_data]\n",
        "\n",
        "            #standardize each schema\n",
        "            for func in functions:\n",
        "                if not isinstance(func, dict):\n",
        "                    continue\n",
        "                normalized= {\n",
        "                    'name': str(func.get('name', '')),\n",
        "                    'description': str(func.get('description', '')),\n",
        "                    'parameters': {\n",
        "                        'type': 'object',    #ensures all schemas declare parameters as key-value pairs\n",
        "                        'properties': func.get('parameters', {}).get('properties', {}),\n",
        "                        'required': sorted(func.get('parameters', {}).get('required', []))\n",
        "                    }\n",
        "                }\n",
        "                schemas.append(normalized)\n",
        "\n",
        "        except (json.JSONDecodeError, AttributeError):\n",
        "            continue\n",
        "\n",
        "    return schemas"
      ],
      "metadata": {
        "id": "ZtqrWKHFFxc3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_user_query(chat_text: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    extract the user query from chat text.\n",
        "    arguments: chat_text:raw text from \"chat\" field\n",
        "    returns: extracted user query (none if not found)\n",
        "    \"\"\"\n",
        "    for line in chat_text.split('\\n'):\n",
        "        if line.startswith(\"USER:\"):\n",
        "            return line[len(\"USER:\"):].strip()\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "YQyFPNIUcZAS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prompt(functions: List[Dict], user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    arguments: functions: list of normalized function schemas, user_query: extracted user question/command\n",
        "    returns: formatted prompt string\n",
        "    \"\"\"\n",
        "    system_part= json.dumps(functions) if functions else \"No functions available\"    #converts list to json string (if list not empty)\n",
        "    return f\"<system>{system_part}</system>\\n<user>{user_query}</user>\""
      ],
      "metadata": {
        "id": "EYN9lbIGGM8V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_target(assistant_text: str) -> Union[Dict, str]:\n",
        "    #match function call pattern\n",
        "    func_call= re.search(\n",
        "        r'<functioncall>\\s*({.*?})\\s*<\\|endoftext\\|>',\n",
        "        assistant_text,\n",
        "        re.DOTALL\n",
        "    )\n",
        "\n",
        "    if not func_call:\n",
        "        #return clean text response if no function call found\n",
        "        return assistant_text.split(\"ASSISTANT:\")[-1].split(\"<|endoftext|>\")[0].strip()\n",
        "\n",
        "    try:\n",
        "        #extract and deep clean JSON string\n",
        "        json_str= func_call.group(1)\n",
        "\n",
        "        #emove all control characters except \\t, \\n, \\r\n",
        "        json_str = ''.join(char for char in json_str if char == '\\t' or char == '\\n' or char == '\\r' or ord(char) >= 32)\n",
        "\n",
        "        #Fix common JSON issues\n",
        "        json_str = (json_str\n",
        "                   .replace(\"'\", '\"')  #Convert single to double quotes\n",
        "                   .replace('\\\\n', ' ')  #Replace newlines with spaces\n",
        "                   .strip())\n",
        "\n",
        "        #Parse with multiple fallback strategies\n",
        "        try:\n",
        "            #first try standard parsing\n",
        "            func_call = json.loads(json_str)\n",
        "        except json.JSONDecodeError as e:\n",
        "            #try fixing common malformations\n",
        "            try:\n",
        "                #handle unquoted property names\n",
        "                json_str = re.sub(r'([{,]\\s*)([a-zA-Z_][a-zA-Z0-9_]*)\\s*:', r'\\1\"\\2\":', json_str)\n",
        "                func_call = json.loads(json_str)\n",
        "            except:\n",
        "                #final fallback: manual extraction\n",
        "                name_match = re.search(r'\"name\"\\s*:\\s*\"([^\"]+)\"', json_str) or \\\n",
        "                            re.search(r'name\\s*:\\s*\"([^\"]+)\"', json_str)\n",
        "\n",
        "                args_match = re.search(r'\"arguments\"\\s*:\\s*(\\{.*?\\}|\"[^\"]*\")', json_str, re.DOTALL) or \\\n",
        "                            re.search(r'arguments\\s*:\\s*(\\{.*?\\}|\"[^\"]*\")', json_str, re.DOTALL)\n",
        "\n",
        "                if not name_match:\n",
        "                    raise ValueError(\"Could not extract function name\")\n",
        "\n",
        "                func_call = {\"name\": name_match.group(1).strip('\"\\'')}\n",
        "\n",
        "                if args_match:\n",
        "                    args_str = args_match.group(1)\n",
        "                    if args_str.startswith('{'):\n",
        "                        try:\n",
        "                            func_call[\"arguments\"] = json.loads(args_str)\n",
        "                        except:\n",
        "                            #try cleaning the arguments JSON\n",
        "                            args_str = args_str.replace(\"'\", '\"')\n",
        "                            args_str = re.sub(r'([{,]\\s*)([a-zA-Z_][a-zA-Z0-9_]*)\\s*:', r'\\1\"\\2\":', args_str)\n",
        "                            try:\n",
        "                                func_call[\"arguments\"] = json.loads(args_str)\n",
        "                            except:\n",
        "                                func_call[\"arguments\"] = {}\n",
        "                    else:\n",
        "                        func_call[\"arguments\"] = {}\n",
        "\n",
        "        #validate and normalize the structure\n",
        "        if not isinstance(func_call, dict):\n",
        "            raise ValueError(\"Function call is not a dictionary\")\n",
        "\n",
        "        if \"name\" not in func_call:\n",
        "            raise ValueError(\"Missing function name\")\n",
        "\n",
        "        #ensure arguments is always a dict\n",
        "        arguments = func_call.get(\"arguments\", {})\n",
        "        if isinstance(arguments, str):\n",
        "            try:\n",
        "                arguments = json.loads(arguments.replace(\"'\", '\"'))\n",
        "            except:\n",
        "                arguments = {}\n",
        "\n",
        "        return {\n",
        "            \"name\": str(func_call[\"name\"]).strip(),\n",
        "            \"arguments\": arguments if isinstance(arguments, dict) else {}\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Invalid function call (recovered): {str(e)}\")\n",
        "        # Return clean text response as fallback\n",
        "        return assistant_text.split(\"ASSISTANT:\")[-1].split(\"<|endoftext|>\")[0].strip()"
      ],
      "metadata": {
        "id": "CtALDR1wdjfr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(original_data: List[Dict]) -> List[Dict]:\n",
        "    processed = []\n",
        "\n",
        "    for entry in original_data:\n",
        "        try:\n",
        "            functions = extract_and_normalize_schemas(entry[\"system\"])\n",
        "            user_query = extract_user_query(entry[\"chat\"])\n",
        "            if not user_query:\n",
        "                continue\n",
        "\n",
        "            prompt = format_prompt(functions, user_query)\n",
        "            target = prepare_target(entry[\"chat\"])\n",
        "\n",
        "            #create consistent structure\n",
        "            is_function_call = isinstance(target, dict)\n",
        "            processed.append({\n",
        "                \"input\": prompt,\n",
        "                \"output\": target,\n",
        "                \"is_function_call\": is_function_call  # At root level\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping entry: {e}\")\n",
        "\n",
        "    return processed\n"
      ],
      "metadata": {
        "id": "YMJ9F5akccHC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_data(dataset: List[Dict]) -> List[Dict]:\n",
        "    tool_calls = [ex for ex in dataset if ex.get(\"is_function_call\", False)]\n",
        "    plain_replies = [ex for ex in dataset if not ex.get(\"is_function_call\", False)]\n",
        "\n",
        "    print(f\"Tool calls: {len(tool_calls)}, Plain replies: {len(plain_replies)}\")\n",
        "\n",
        "    if not tool_calls or not plain_replies:\n",
        "        print(\"Warning: Could not balance - returning all data\")\n",
        "        return dataset\n",
        "\n",
        "    min_len = min(len(tool_calls), len(plain_replies))\n",
        "    return tool_calls[:min_len] + plain_replies[:min_len]"
      ],
      "metadata": {
        "id": "3nPGlB0jE4MC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "additional_examples = [\n",
        "    {\n",
        "        \"system\": \"SYSTEM: You are a helpful assistant.\\n[]\",\n",
        "        \"chat\": \"USER: Hi, how are you?\\nASSISTANT: I'm doing well, thanks! <|endoftext|>\"\n",
        "    },\n",
        "    {\n",
        "        \"system\": \"SYSTEM: You are a helpful assistant.\\n[]\",\n",
        "        \"chat\": \"USER: What's 2+2?\\nASSISTANT: The answer is 4. <|endoftext|>\"\n",
        "    }\n",
        "]\n",
        "data.extend(additional_examples)"
      ],
      "metadata": {
        "id": "XujFnFPUMeQV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(balanced_data: List[Dict]) -> Dataset:\n",
        "    return Dataset.from_list([\n",
        "        {\n",
        "            \"input\": x[\"input\"],\n",
        "            \"output\": json.dumps(x[\"output\"]) if isinstance(x[\"output\"], dict) else x[\"output\"],\n",
        "            \"is_function_call\": x[\"is_function_call\"]\n",
        "        }\n",
        "        for x in balanced_data\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "r_LzgsojbaL_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed = process_dataset(data)\n",
        "balanced = balance_data(processed)\n",
        "train_data = create_dataset(balanced)"
      ],
      "metadata": {
        "id": "DMmiEOAvcgex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d2d04f-7c07-4b39-a05a-a7927f01b975"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool calls: 63212, Plain replies: 49750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Raw data count: {len(data)}\")\n",
        "print(f\"Processed data count: {len(processed)}\")\n",
        "print(f\"Balanced data count: {len(balanced)}\")\n",
        "print(f\"Final train_dataset size: {len(train_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuXK0_EV5fs5",
        "outputId": "db8ebef0-13ab-4760-a863-b536d6b0b845"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw data count: 112962\n",
            "Processed data count: 112962\n",
            "Balanced data count: 99500\n",
            "Final train_dataset size: 99500\n"
          ]
        }
      ]
    }
  ]
}